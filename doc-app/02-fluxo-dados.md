# ðŸ”„ Fluxo de Dados no BesuScan

## ðŸ“‹ VisÃ£o Geral

O BesuScan processa dados da blockchain atravÃ©s de um fluxo bem definido que garante consistÃªncia, performance e confiabilidade. Este documento detalha como os dados fluem desde a captura na blockchain atÃ© a apresentaÃ§Ã£o no frontend.

## ðŸŒŠ Fluxo Principal de Dados

```mermaid
graph TD
    A[Hyperledger Besu Node] --> B[Indexer - WebSocket Listener]
    B --> C[RabbitMQ - Event Bus]
    C --> D[Worker - Event Processor]
    D --> E[PostgreSQL - Primary Storage]
    D --> F[Redis - Cache Layer]
    E --> G[API REST]
    F --> G
    G --> H[Frontend React]

    subgraph "Real-time Updates"
        I[WebSocket Server] --> H
        G --> I
    end

    subgraph "Analytics Pipeline"
        E --> J[Analytics Processor]
        J --> K[Metrics Tables]
        K --> G
    end
```

## ðŸ“Š Tipos de Dados Processados

### 1. **Dados de Blocos**
- **Origem**: Besu node via `eth_subscribe("newHeads")`
- **FrequÃªncia**: ~4 segundos (QBFT consensus)
- **Volume**: ~1 bloco/4s = 21.600 blocos/dia
- **Processamento**: Tempo real + batch

### 2. **Dados de TransaÃ§Ãµes**
- **Origem**: Blocos minerados + mempool
- **FrequÃªncia**: VariÃ¡vel (0-100+ tx/bloco)
- **Volume**: Dependente da atividade da rede
- **Estados**: pending â†’ mined (success/failed)

### 3. **Eventos de Contratos**
- **Origem**: Transaction receipts + logs
- **FrequÃªncia**: Por transaÃ§Ã£o que interage com contratos
- **Volume**: 0-N eventos por transaÃ§Ã£o
- **Tipos**: Transfer, Approval, Custom events

### 4. **Dados de Contas**
- **Origem**: TransaÃ§Ãµes + state queries
- **FrequÃªncia**: Por atividade da conta
- **Volume**: Crescimento incremental
- **MÃ©tricas**: Saldo, nonce, atividade

## ðŸ”„ Fases do Processamento

### **Fase 1: Captura (Indexer)**

#### **1.1 Block Listener**
```
Besu WebSocket â†’ New Block Header â†’ Extract Block Data â†’ Validate â†’ Queue
```

**Processo Detalhado**:
1. ConexÃ£o WebSocket permanente com Besu
2. SubscriÃ§Ã£o para `newHeads`
3. Recebimento de header do novo bloco
4. Busca de dados completos via RPC
5. ValidaÃ§Ã£o de integridade
6. PublicaÃ§Ã£o na fila `blocks.new`

**Dados Capturados**:
- NÃºmero e hash do bloco
- Timestamp e minerador
- Gas usado e limite
- NÃºmero de transaÃ§Ãµes
- Merkle roots e metadados

#### **1.2 Transaction Listener**
```
Block Data â†’ Extract Transactions â†’ Decode Methods â†’ Queue
```

**Processo Detalhado**:
1. ExtraÃ§Ã£o de transaÃ§Ãµes do bloco
2. AnÃ¡lise de input data
3. DecodificaÃ§Ã£o de mÃ©todos de contratos
4. ClassificaÃ§Ã£o por tipo
5. PublicaÃ§Ã£o na fila `transactions.new`

#### **1.3 Event Listener**
```
Transaction Receipt â†’ Extract Logs â†’ Decode Events â†’ Queue
```

**Processo Detalhado**:
1. ObtenÃ§Ã£o de receipts das transaÃ§Ãµes
2. ExtraÃ§Ã£o de logs/eventos
3. DecodificaÃ§Ã£o automÃ¡tica de eventos conhecidos
4. ClassificaÃ§Ã£o por contrato e tipo
5. PublicaÃ§Ã£o na fila `events.new`

### **Fase 2: Processamento (Worker)**

#### **2.1 Block Processing**
```
Queue Message â†’ Fetch Full Data â†’ Transform â†’ Batch â†’ Persist
```

**Pipeline de Processamento**:
1. **DeserializaÃ§Ã£o**: Converter mensagem JSON
2. **Enrichment**: Buscar dados completos no Besu
3. **Transformation**: Converter para entidades de domÃ­nio
4. **Validation**: Verificar integridade e consistÃªncia
5. **Batching**: Agrupar para inserÃ§Ã£o eficiente
6. **Persistence**: Inserir no PostgreSQL
7. **Caching**: Atualizar cache Redis

#### **2.2 Transaction Processing**
```
Queue Message â†’ Decode Input â†’ Calculate Fees â†’ Update Accounts â†’ Persist
```

**Enriquecimento de Dados**:
- DecodificaÃ§Ã£o de mÃ©todos de contratos
- CÃ¡lculo de fees (gas * price)
- ClassificaÃ§Ã£o de tipo de transaÃ§Ã£o
- AtualizaÃ§Ã£o de mÃ©tricas de contas
- Rastreamento de interaÃ§Ãµes

#### **2.3 Event Processing**
```
Queue Message â†’ Decode ABI â†’ Extract Participants â†’ Update Analytics â†’ Persist
```

**Processamento Especializado**:
- **ERC-20**: Transfer, Approval events
- **ERC-721**: NFT transfers
- **ERC-1155**: Multi-token operations
- **Custom**: Eventos especÃ­ficos de contratos
- **Factory**: CriaÃ§Ã£o de novos contratos

### **Fase 3: Armazenamento**

#### **3.1 PostgreSQL (Primary Storage)**
```
Batch Data â†’ Transaction â†’ Insert/Update â†’ Commit â†’ Index Update
```

**EstratÃ©gias de InserÃ§Ã£o**:
- **Batch Inserts**: 10-50 registros por lote
- **Upsert Operations**: INSERT ON CONFLICT UPDATE
- **Transaction Safety**: Rollback em caso de erro
- **Index Maintenance**: AtualizaÃ§Ã£o automÃ¡tica

#### **3.2 Redis (Cache Layer)**
```
Critical Data â†’ Serialize â†’ Set with TTL â†’ Expire Management
```

**Camadas de Cache**:
- **L1 (30s TTL)**: Ãšltimo bloco, stats bÃ¡sicas
- **L2 (30min TTL)**: Blocos individuais, contratos
- **L3 (24h TTL)**: Dados histÃ³ricos, analytics

### **Fase 4: Servir Dados (API)**

#### **4.1 Query Processing**
```
HTTP Request â†’ Parse â†’ Cache Check â†’ Database Query â†’ Transform â†’ Response
```

**OtimizaÃ§Ãµes**:
- **Cache First**: Verificar Redis antes do banco
- **Query Optimization**: Usar Ã­ndices apropriados
- **Result Pagination**: Limitar resultados
- **Response Caching**: Cache de responses HTTP

#### **4.2 Real-time Updates**
```
Data Change â†’ WebSocket Broadcast â†’ Client Update
```

**Canais WebSocket**:
- `blocks`: Novos blocos
- `transactions`: TransaÃ§Ãµes recentes
- `events`: Eventos de contratos
- `stats`: EstatÃ­sticas da rede

## âš¡ OtimizaÃ§Ãµes de Performance

### **1. Parallel Processing**
```go
// Processamento paralelo de blocos
for i := 0; i < numWorkers; i++ {
    go func(workerID int) {
        for block := range blockChannel {
            processBlock(block)
        }
    }(i)
}
```

### **2. Batch Operations**
```sql
-- InserÃ§Ã£o em lote otimizada
INSERT INTO transactions (hash, block_number, from_address, ...)
VALUES
    ($1, $2, $3, ...),
    ($4, $5, $6, ...),
    ($7, $8, $9, ...)
ON CONFLICT (hash) DO UPDATE SET ...;
```

### **3. Smart Caching**
```go
// Cache inteligente com TTL variÃ¡vel
func (c *Cache) Set(key string, value interface{}, category string) {
    var ttl time.Duration
    switch category {
    case "hot":
        ttl = 30 * time.Second
    case "warm":
        ttl = 30 * time.Minute
    case "cold":
        ttl = 24 * time.Hour
    }
    c.redis.Set(key, value, ttl)
}
```

## ðŸ“Š MÃ©tricas de Fluxo

### **Throughput Metrics**
- **Indexer**: 1000+ blocos/segundo (sync mode)
- **Worker**: 500+ transaÃ§Ãµes/segundo
- **API**: 10000+ requests/segundo
- **Cache Hit Rate**: 85-95%

### **Latency Metrics**
- **Block to Database**: < 200ms
- **Event Processing**: < 100ms
- **API Response**: < 50ms (cached)
- **WebSocket Update**: < 10ms

### **Data Volume**
- **Daily Blocks**: ~21,600
- **Daily Transactions**: VariÃ¡vel (0-100k+)
- **Daily Events**: VariÃ¡vel (0-1M+)
- **Database Growth**: ~100MB/day (mÃ©dia)

## ðŸ”„ Estados dos Dados

### **Transaction States**
```mermaid
stateDiagram-v2
    [*] --> Pending
    Pending --> Mined
    Pending --> Dropped
    Mined --> Success
    Mined --> Failed
    Dropped --> [*]
    Success --> [*]
    Failed --> [*]
```

### **Block States**
```mermaid
stateDiagram-v2
    [*] --> Detected
    Detected --> Processing
    Processing --> Processed
    Processing --> Failed
    Failed --> Retry
    Retry --> Processing
    Processed --> Cached
    Cached --> [*]
```

## ðŸ”§ Tratamento de Erros

### **Error Recovery Pipeline**
```
Error Detection â†’ Classification â†’ Retry Logic â†’ Dead Letter Queue â†’ Alert
```

### **Retry Strategies**
1. **Exponential Backoff**: Para erros temporÃ¡rios
2. **Circuit Breaker**: Para falhas de serviÃ§os
3. **Dead Letter Queue**: Para erros permanentes
4. **Manual Intervention**: Para casos complexos

### **Error Categories**
- **Network Errors**: ReconexÃ£o automÃ¡tica
- **Data Errors**: ValidaÃ§Ã£o e sanitizaÃ§Ã£o
- **Database Errors**: Retry com backoff
- **Business Logic Errors**: Log e investigaÃ§Ã£o

## ðŸ“ˆ Monitoramento do Fluxo

### **Key Performance Indicators (KPIs)**
```
- Block Processing Rate: blocos/segundo
- Transaction Processing Rate: tx/segundo
- Event Processing Rate: eventos/segundo
- API Response Time: milissegundos
- Cache Hit Rate: percentual
- Error Rate: erros/minuto
- Queue Depth: mensagens pendentes
```

### **Alertas AutomÃ¡ticos**
- Block processing delay > 30 segundos
- Queue depth > 1000 mensagens
- Error rate > 1% por minuto
- Cache hit rate < 80%
- Database connection failures

### **Dashboards Grafana**
1. **Data Flow Overview**: VisÃ£o geral do fluxo
2. **Performance Metrics**: MÃ©tricas de performance
3. **Error Tracking**: Rastreamento de erros
4. **Capacity Planning**: Planejamento de capacidade

## ðŸ”’ Garantias de ConsistÃªncia

### **ACID Properties**
- **Atomicity**: TransaÃ§Ãµes completas ou rollback
- **Consistency**: Dados sempre vÃ¡lidos
- **Isolation**: OperaÃ§Ãµes concorrentes isoladas
- **Durability**: Dados persistidos permanentemente

### **Data Integrity Checks**
- Hash validation para blocos
- Merkle root verification
- Transaction signature validation
- Balance consistency checks

### **Eventual Consistency**
- Cache pode estar temporariamente inconsistente
- SincronizaÃ§Ã£o automÃ¡tica via TTL
- Manual cache invalidation quando necessÃ¡rio

## ðŸš€ Escalabilidade Horizontal

### **Sharding Strategy**
- **Database Sharding**: Por data/bloco
- **Queue Sharding**: Por tipo de evento
- **Cache Sharding**: Por namespace
- **API Sharding**: Por endpoint

### **Load Balancing**
- **Database**: Read replicas
- **Cache**: Redis cluster
- **API**: Multiple instances
- **Workers**: Auto-scaling

---

[â¬…ï¸ Voltar: Arquitetura](./01-arquitetura.md) | [âž¡ï¸ PrÃ³ximo: Tecnologias](./03-tecnologias.md)
